>参考《计算机操作系统教程（第3版）》

* [一、绪论](#1)
  - [操作系统概念](#1.1)
  - [操作系统功能](#1.2)
* [二、操作系统用户界面](#2)
  - [简介](#2.1)
  - [系统调用](#2.2)
* [三、进程管理](#3)
  - [并行与并发](#3.1)
  - [进程与线程](#3.2)
  - [进程状态及其转换](#3.3)
  - [互斥与同步](#3.4)
  - [死锁](#3.5)
* [四、处理机调度](#4)
  - [进程调度算法](#4.1)
* [五、存储管理](#5)
  - [存储管理功能](#5.1)
  - [分区存储管理](#5.2)
  - [页式管理](#5.3)
<h1 id="1">一、绪论</h1>
<h2 id="1.1">操作系统概念</h2>
操作系统是计算机系统中的一个系统软件，他是这样一些程序模块的集合——他们管路和控制计算机系统中的硬件资源，合理地组织计算机工作流程，以便有效地利用这些资源为用户提供一个具有足够的功能、使用方便、可扩展、安全和可管理的工作环境，从而在计算机与其用户之间起到接口的作用。
<h2 id="1.2">操作系统功能</h2>

### 1. 处理器管理
解决对处理机分配调度策略、分配实施和资源回收等问题。
### 2. 存储器管理
对存储器进行分配、保护、扩充和管理。
### 3. 设备管理
通道、控制器、输入输出设备的分配和管理。

设备独立性。
### 4. 文件系统管理
信息的共享、保密和保护
### 5. 用户接口
一种用户接口是程序一级的接口，即提供一组广义指令（或称系统调用、程序请求）供用户程序和其他系统程序调用。

另一种接口是作业一级的接口，提供一组控制操作命令供用户去组织和控制自己作业的运行。

###### 写总结的时候，才发现这本书的概论是真的有问题，和后面章节的具体内容不是很对的上 ######
<h1 id="2">二、操作系统用户界面</h1>
<h2 id="2.1">简介</h2>
针对不同的用户，操作系统提供不同的用户界面，其中普通用户和管理员用户的界面是一组不同操作命令组成的集合，他们分别实现用户所要求的不同功能，为用户提供相应的服务；对编程人员提供的是一组系统调用的集合，这些系统调用允许编程人员使用操作系统和程序，开发能够满足用户服务需求的新的控制命令。
<h2 id="2.2">系统调用</h2>
系统调用是操作系统提供给编程人员的唯一接口。

分类：

设备管理、文件管理、进程控制、进程通信、存储管理、线程管理
<h1 id="3">三、进程管理</h1>
<h2 id="3.1">并行与并发</h2>

### 1. 并行
一组在逻辑上互相独立的程序或程序段在执行过程中，其执行时间在客观上互相重叠。
### 2. 并发
一组程序按独立的、异步的速度执行。并行执行不等于时间上的重叠。
<h2 id="3.2">进程与线程</h2>

### 1. 进程
并发执行的程序在执行过程中分配和管理资源的基本单位。
### 2. 线程
是进程的一部分。是CPU调度的基本单位。
### 3. 区别
* 除了CPU之外，计算机内的软硬件资源的分配与线程无关，线程只能共享他所属进程的资源。
* 进程拥有一个完整的虚拟地址空间。
* 进程不依赖于线程而独立存在。
* 线程是进程的一部分，它没有自己的地址空间，它和进程内的其他线程一起共享该进程的所有资源。
<h2 id="3.3">进程状态及其转换</h2>

![图片](https://github.com/UMRhamster/Jobs2018/raw/master/operating%20system/process_status.png)
* 初始态
* 执行状态
* 等待状态：进程因等待某个事件发生而放弃处理机进入等待状态。
* 就绪状态：已经得到除了CPU之外的其它资源，只要由调度得到处理机，便可立即投入执行。
* 终止状态
<h2 id="3.4">互斥与同步</h2>

### 1. 临界区
不允许多个并发进程交叉执行的一段程序。
### 2. 进程互斥
不允许两个以上的共享该资源的并发进程同时进入临界区称为互斥。
### 3. 进程同步
异步环境下的一组并发进程，因直接制约而互相发送消息而进行互相合作、互相等待，使得各进程按一定的速度执行的过程称为进程间的同步。
### 4. 信号量
信号量管理相应临界区的共有资源，它代表可用资源实体。信号量的数值仅能由P，V原语操作改变。
* P原语操作：
  1. 信号量-1
  2. 若信号量-1后仍大于或等于零，则P原语返回，该进程继续执行。
  3. 若信号量-1后相遇零，则该进程被阻塞后与该信号量相对的队列中，然后转进程调度。
* V原语操作：
  1. 信号量+1
  2. 若相加结果大于零，V原语停止执行，该进程返回调用处，继续执行。
  3. 若相加结果小于或等于零，则从该信号的等待队列中唤醒一等待进程，然后再返回原进程继续执行或转进程调度。
#### 生产者-消费者问题
把并发进程的同步和异步问题一般化，可以得到一个抽象的一般模型，即生产者-消费者模型。

    deposit(data):
        begin
            P(avail)
            P(mutix)
            数据送入缓冲区某单元
            V(full)
            V(mutix)
        end
    
    remove(data)
        begin
            P(full)
            P(mutix)
            取缓冲区中某单元数据
            V(avail)
            V(mutix)
        end
<h2 id="3.5">死锁</h2>

各并发进程彼此互相等待对方所拥有的资源，且这些并发进程在的得到对方的资源之前不会释放自己所拥有的资源。从而造成大家想要的得到资源而又得不到资源，各并发进程不能继续向前推进的状态。

![图片](https://github.com/UMRhamster/Jobs2018/raw/master/operating%20system/deadlock.png)
### 1. 产生死锁的必要条件
* 互斥条件。并发进程所要求和占有的资源是不能同时被两个以上进程使用或操作的，进程对它所需要的资源进行排他性控制。
* 不剥夺条件。进程所获得的资源在未使用完毕之前，不能被其他进程强行剥夺，而只能由获得该资源的进程自己释放。
* 部分分配。进程每次申请它所需要的一部分资源，在等待新资源的同时，继续占用已分配到的资源。
* 环路条件。存在一种进程循环链，链中每一个进程已获得的资源同时被下一个进程所请求。
### 2. 死锁的排除方法
* 死锁预防
  
  采取某种策略，限制并发进程对资源的请求，从而破坏产生死锁的必要条件中的一个或者几个来防止发生死锁。

  （一）打破“互斥”条件

  允许进程同时访问某些资源等。

  （二）破环“不可剥夺”条件
  当进程有新的资源请求时，如果得不到满足，要先释放原先占有的资源，待以后重新申请。

  （三）破坏“部分分配”条件

  运行前（创建时），一次性分配给进程它所需的全部资源。如果某个进程所需要的全部资源得不到满足时，则不分配任何资源，此进程暂不运行。

  （四）破坏“环路等待”条件

  把系统资源按类型排序（例如打印机为1、磁带机为2、磁盘为3、等等） ，进程要按照资源的序号递增的次序提出资源申请。
* 死锁避免
  
  死锁避免可被称为动态预防，因为系统采用动态分配资源，在分配过程中预测出死锁发生的可能性并加以避免的方法。
  #### 银行家算法
  在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。

  安全序列是指一个进程序列{P1，…，Pn}是安全的，即对于每一个进程Pi(1≤i≤n），它以后尚需要的资源量不超过系统当前剩余资源量与所有进程Pj (j < i )当前占有资源量之和。（即在分配过程中，不会出现某一进程后续需要的资源量比其他所有进程及当前剩余资源量总和还大的情况）

  注：存在安全序列则系统是安全的，如果不存在则系统不安全，但不安全状态不一定引起死锁。
* 死锁检测和恢复
  
  当进程进行资源请求时死锁检测算法检查并发进程组是否构成资源的请求和保持环路。死锁的恢复方法较多。最简单的办法是终止各锁住进程，或按一定顺序中止进程序列，直至已释放到有足够的资源来完成剩下的进程时为止。另外，也可以从被锁住进程强迫剥夺资源以解除死锁。
<h1 id="4">四、处理机调度</h1>
<h2 id="4.1">进程调度算法</h1>

### 1. 先来先服务(FCFS)调度算法
将就绪进程按提交顺序或变为就绪状态的先后排成队列，并按照先来先服务(first come first serve)的方式进行处理，是一种最普遍和最简单的方式。

对于那些执行时间较短的作业或进程来说，如果它们在某些执行时间很长的作业或进程之后到达，则它们将等待很长的时间。
### 2. 轮转法
轮转法的基本思路是让每个进程在就绪队列中的等待时间与享受服务的时间成比例。轮转法的基本概念是将CPU的处理时间分成固定大小的时间片。
### 3. 最短作业优先法
选择那些估计需要执行时间最短的作业投入执行，为它们创建进程和分配资源。

最短作业优先法有可能使得那些长作业永远得不到调度执行的机会。
### 4. 最高响应比优先法
最高响应比优先法是对先来先服务法和最短作业优先法的一种综合平衡。最高响应比算法同时考虑每个作业的等待时间长短和估计需要的执行时间长短，从中选出响应比最高的作业投入执行。
<center>响应比：R=(W+T)/T = 1+W/T</center>
其中T为该进程估计需要的时间，W为作业在后备状态队列中的等待时间。

<h1 id="5">五、存储管理</h1>
<h2 id="5.1">存储管理的功能</h1>

### 1. 虚拟存储器
将进程中的目标代码、数据等的虚拟地址组成的虚拟空间称为虚拟存储器。
### 2. 地址变换
将虚拟地址映射为内存地址的问题。
实现地址重定位的方法有两种：静态地址重定位和动态地址重定位。
### 3. 内存的分配和回收
### 4. 内存信息的共享和保护
上下界保护法、保护键法
<h2 id="5.2">分区存储管理</h1>
其基本原理是给每一个内存中的进程划分一块适当大小的存储区，以连续存储各进程的程序和数据，使各进程得以并发执行。

* ### 固定分区法
  把内存固定划分为若干个大小不等的区域。
* ### 动态分区法
  在作业执行前并不建立分区，分区的建立是在作业的处理过程中进行的，且其大小可随作业或进程对内存的要求而改变。
  #### 动态分区的分配方法
  * 最先适应法
  
    要求可用表或自由链按其实地址递增的次序排列，一旦找到大于或等于所要求内存长度的分区，则探索结束。
  * 最佳适应法

    要求从小到大的次序组成空闲区可用表或自由链。
  * 最坏适应法

    要求空闲区按其大小递减的顺序组成空闲区可用表或自由链。

  分区式管理方式实现方式较为简单，但存在着严重的碎片问题使得内存的利用率不高。
<h2 id="5.3">页式管理</h1>
把进程的虚拟空间被划分成若干个长度相等的页，还把内存空间也按页的大小划分为片或页面。页式管理采用请求调用或预调用技术实现了内外存储器的统一管理。

### 1. 地址变换
 <center><img src="https://github.com/UMRhamster/Jobs2018/raw/master/operating%20system/page_management.png"/></center>

    例：有一系统采用页式存储管理，有一作业大小是8KB，页大小为2KB，依次装入内存的第7、9、10、5块，试将虚地址7145，3412转换成内存地址。

    (1) 虚地址 7145
    P＝INT [7145/2048] ＝3
    W＝7145 mod 2048＝1001
    内存地址: 5*2048+1001=11241

    (2) 虚地址 3412
    P＝INT [3412/2048] ＝1
    W＝ 3412 mod 2048＝1364
    内存地址： 9*2048+1364=19796
### 2. 请求页式管理中的置换算法
页面置换算法在内存中没有空闲页面时被调用。它的目的是选出一个被淘汰的页面。如果内存中有足够的空闲页面存放所调入的页，则不必使用置换算法。把内存和外存统一管理的真正目的是把那些被访问概率非常高的页存放在内存中。因此，置换算法应该置换那些被访问概率最低的页，将它们移除内存。
* ### 随机淘汰算法
  随机选择某个用户的页面并将其换出。
* ### 先进先出算法
  选择在内存驻留时间最长的页将其淘汰。
* ### 最近最久未使用算法
  当需要淘汰某一页时，选择离当前时间最近的一段时间内最久没有使用过的页先淘汰。即当需要淘汰一页时，选择最长时间未使用的页
  <center>
  <table border="1">
  <tr>
  <td>7</td><td>0</td><td>1</td><td>2</td><td>0</td><td>3</td><td>0</td><td>4</td><td>2</td><td>3</td><td>0</td><td>3</td><td>2</td><td>1</td><td>2</td><td>0</td><td>1</td>
  </tr>
  <tr>
  <td>7</td><td>7</td><td>7</td><td>2</td><td>2</td><td>2</td><td>2</td><td>4</td><td>4</td><td>4</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td>
  </tr>
  <tr>
  <td></td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>3</td><td>3</td><td>3</td><td>3</td><td>3</td><td>0</td><td>0</td>
  <tr>
  <td></td><td></td><td>1</td><td>1</td><td>1</td><td>3</td><td>3</td><td>3</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td>
  </tr>
  </tr>
  </table>
  </center>
  要完全实现LRU算法需花费巨大的系统开销（必须对每一个页面都设置有关的访问记录项，而且每一次访问都必须更新这些记录）。常用的近似算法：

  - 最不经常使用页面淘汰算法LFU(least fraquently used)
  
     需要淘汰某一页时，首先淘汰到当前时间为止，被访问次数最少的那一页

  - 最近没有使用页面淘汰算法NUR

    需要淘汰某一页时，从那些最近一个时期未被访问的页中任选一页淘汰。

  - 理想型淘汰算法OPT(optional replacement algorithm)

    当要调入一新页而必须淘汰一旧页时，所淘汰的页是以后不再使用的，或者是以后相当长的时间内不会使用的。
  




    
